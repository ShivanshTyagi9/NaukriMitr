{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eca053d-76bc-4c00-88c4-9c214e3c170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shive\\.conda\\envs\\yolo_env1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import torch\n",
    "import contractions\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, T5Tokenizer, T5ForConditionalGeneration\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import load_dataset\n",
    "import google.generativeai as genai\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ec661c-f3fd-4b79-a244-6d6838c89b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
      "   -------------------- ----------------- 524.3/992.0 kB 558.9 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 524.3/992.0 kB 558.9 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 786.4/992.0 kB 578.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 992.0/992.0 kB 248.4 kB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217d2b2b-3d3d-4b98-99d9-29c5857026c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyCShW_UD_Gpiv6N7Hhn7sdif4GQxKRYIzg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdcc81-6f7b-4f30-947a-b33c03b665a7",
   "metadata": {},
   "source": [
    "## Extract from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5acbbeae-ac37-4bc2-90eb-ef8ec0a35c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(pdf_path):\n",
    "    \"\"\"Extract all text from a PDF file using pdfplumber.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            resume_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    resume_text += \" \" + page_text\n",
    "        return resume_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808ef9a7-7be1-47f7-ae0f-74e3732c537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_information('Shivansh_Tyagi_Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7078971c-20aa-4a22-bdea-80ccb699b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shivansh Tyagi\n",
      "# shivelite2003@gmail.com (cid:132) +91-7456833022 (cid:240) Shivansh Tyagi § ShivanshTyagi9\n",
      "Summary\n",
      "SkilledinPython,dataanalysis,andmachinelearning,withexperienceinbuildingpredictivemodels,automation\n",
      "tools, and interactive applications.\n",
      "Education\n",
      "Raj Kumar Goel Institute of Technology Ghaziabad, UP\n",
      "B.Tech in Computer Science and Engineering Expeted Graduation, 2026\n",
      "◦ Concentrations: Computational Fundamentals\n",
      "◦ CGPA: 8\n",
      "◦ Coursework: Data Structure and Algorithms, Operating System, Database Management System, Com-\n",
      "puter Architecture, Machine Learning, OOPS\n",
      "Projects\n",
      "Handwritten-Digit-Recognition github repo 2\n",
      "◦ Used TensorFlow and Keras to develop a Convolutional Neural Network (CNN) for handwritten digit\n",
      "recognition with the MNIST dataset, achieving 99.12 accuracy, enhancing classification performance and\n",
      "model efficiency.\n",
      "◦ Used MNIST dataset to train the model.\n",
      "◦ Tools used: Python, NumPy, Pandas, Tensorflow / Keras, Matplotlib\n",
      "Fruits and Vegetable Classifier github repo 2\n",
      "◦ UsedResNetandEfficientNetarchitecturestoclassifyfruitsandvegetablesimages,achieving 96and94\n",
      "accuracy, which demonstrated effective generalization and model performance.\n",
      "◦ Performed hyperparameter tuning and applied data augmentation techniques to improve model robustness\n",
      "and enhance classification accuracy.\n",
      "◦ Worked with the Kaggle Fruits and Vegetables Image Recognition dataset, containing more than 33,000\n",
      "images in 36 classes, to train and evaluate the models.\n",
      "◦ TensorFlow, Python, and Matplotlib were used for modeling implementation, training, evaluation, and\n",
      "visualization of results.\n",
      "Spoti-Save github repo 2\n",
      "◦ EngineeredaPython-basedapplicationusingSpotifyAPItofetchlikedsongs,YouTubeDataAPIforvideo\n",
      "searches, and yt-dlp for mp3 downloads.\n",
      "◦ IntegratedmooddetectionthroughNLPtogeneratepersonalizedplaylistsbymappingSpotifyaudiofeatures\n",
      "to user mood.\n",
      "◦ Designed automated pipeline for storing metadata and optimizing batch processing for offline playback.\n",
      "Skills\n",
      "Languages: Python, Java, C\n",
      "Libraries: Pandas, Numpy, Tensorflow, Matplotlib, Flask\n",
      "Achievements\n",
      "◦ Rated 2 stars (1503 rating) on Codechef.\n",
      "◦ Rated Newbie(1127) on Codeforces.\n",
      "◦ Secured 1st place in college Code Clash event, awarded by Striver.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad13a8aa-8505-4122-ab8b-5487fdc9746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_extract_skills(project_text):\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "    try:\n",
    "        response = model.generate_content(f\"Extract skills from the following project description and return only a python list of skiils:\\n{project_text}\")\n",
    "        skills = (response.text)\n",
    "        skills = skills.replace(\"python\", \"\").strip()\n",
    "        skills = skills.replace(\"```\", \"\").strip()\n",
    "        extracted_list = ast.literal_eval(skills)\n",
    "        return extracted_list\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Gemini API:\", e)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22b299a8-5056-49d7-a8d6-dc35cb88dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details(resume_text):\n",
    "    \"\"\"\n",
    "    Extract Skills, Education, and Projects sections using regex,\n",
    "    then augment the Skills by calling the Gemini API on the Projects section.\n",
    "    \"\"\"\n",
    "    # Define regex patterns for each section\n",
    "    skills_pattern = r'(?:(?:Technical|Professional|Tech)\\s+)?Skills\\s*\\n([\\s\\S]*?)(?=\\n[A-Z][a-z]+\\b|\\Z)'\n",
    "    education_pattern = r'Education\\s*\\n([\\s\\S]*?)(?=\\n[A-Z][a-z]*\\n|$)'\n",
    "    projects_pattern = r'Projects\\s*\\n([\\s\\S]*?)(?=\\n\\s*\\n|$)'\n",
    "    \n",
    "    # Extract sections using regex\n",
    "    skills_match = re.findall(skills_pattern, resume_text, re.DOTALL)\n",
    "    education_match = re.findall(education_pattern, resume_text, re.DOTALL)\n",
    "    projects_match = re.findall(projects_pattern, resume_text, re.DOTALL)\n",
    "    \n",
    "    # Get the first match for each section if available\n",
    "    skills = skills_match[0] if skills_match else \"\"\n",
    "    education = education_match[0] if education_match else \"\"\n",
    "    projects = projects_match[0] if projects_match else \"\"\n",
    "    \n",
    "    # If the Projects section is found, call the Gemini API to extract additional skills\n",
    "    additional_skills = \"\"\n",
    "    if projects:\n",
    "        # Assume gemini_extract_skills(projects) returns a list of skills\n",
    "        extracted_skills = gemini_extract_skills(projects)\n",
    "        if extracted_skills:\n",
    "            additional_skills = \" \".join(extracted_skills)\n",
    "    \n",
    "    # Combine the original skills with the additional skills from projects\n",
    "    combined_skills = skills + \" \" + additional_skills if additional_skills else skills\n",
    "    \n",
    "    return {\n",
    "        'Skills': combined_skills.strip(),\n",
    "        'Education': education.strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d47b559-b107-47b8-be4b-6b4f64bda1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = extract_details(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8049b7ce-ca1c-425e-bbc2-49d973343505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Skills': 'Languages: Python, Java, C TensorFlow Keras Convolutional Neural Networks (CNN) MNIST dataset Classification Model Efficiency ResNet EfficientNet Hyperparameter Tuning Data Augmentation Kaggle Fruits and Vegetables Image Recognition dataset Python Matplotlib Spotify API YouTube Data API yt-dlp NLP Mood Detection Pandas Numpy Flask', 'Education': 'Raj Kumar Goel Institute of Technology Ghaziabad, UP\\nB.Tech in Computer Science and Engineering Expeted Graduation, 2026\\n◦ Concentrations: Computational Fundamentals\\n◦ CGPA: 8\\n◦ Coursework: Data Structure and Algorithms, Operating System, Database Management System, Com-\\nputer Architecture, Machine Learning, OOPS'}\n"
     ]
    }
   ],
   "source": [
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8036b855-ddef-4c15-b1e0-5ea1b7fb79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text for embedding.\"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercase and trim\n",
    "    text = text.lower().strip()\n",
    "    # Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    # Remove URLs, emails, phone numbers\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\b\\d{1,3}[-./]?\\d{1,3}[-./]?\\d{1,4}\\b', '', text)\n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68637fdc-722f-4a98-bd6b-d33bf528f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def build_candidate_dataset(data_folder='data'):\n",
    "    \"\"\"\n",
    "    Walk through the data folder (with subfolders by category),\n",
    "    extract resume text from each PDF, extract details (Skills, Education),\n",
    "    and store metadata.\n",
    "    \"\"\"\n",
    "    candidate_data = []\n",
    "    for category in os.listdir(data_folder):\n",
    "        category_path = os.path.join(data_folder, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for file in os.listdir(category_path):\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    pdf_path = os.path.join(category_path, file)\n",
    "                    full_text = extract_information(pdf_path)\n",
    "                    details = extract_details(full_text)\n",
    "                    # Use filename (without extension) as unique ID\n",
    "                    candidate_id = os.path.splitext(file)[0]\n",
    "                    candidate_data.append({\n",
    "                        'ID': candidate_id,\n",
    "                        'Category': category,\n",
    "                        'Skills': details.get('Skills', ''),\n",
    "                        'Education': details.get('Education', '')\n",
    "                    })\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(candidate_data)\n",
    "    # Optionally, remove resumes where both Skills and Education are missing\n",
    "    df = df[~((df['Skills'] == \"\") & (df['Education'] == \"\"))].reset_index(drop=True)\n",
    "    print(df)\n",
    "    print(\"\\n----------------\\n\")\n",
    "    # Concatenate Skills and Education to form the complete CV text\n",
    "    df['CV'] = (df['Skills'] + \" \" + df['Education']).fillna(\"\")\n",
    "    print(df)\n",
    "    print(\"\\n----------------\\n\")\n",
    "    # Clean the concatenated CV text\n",
    "    df['CV'] = df['CV'].apply(text_cleaning)\n",
    "    print(df)\n",
    "    print(\"\\n----------------\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8306d191-9360-47a9-b02c-ec24f4144467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ID Category  \\\n",
      "0  Shivansh_Tyagi_Resume        1   \n",
      "1   Rajat_Gupta_Resume 1        2   \n",
      "2       Alok_kumar_yadav        3   \n",
      "3  SanchitChauhan_Rename        4   \n",
      "\n",
      "                                              Skills  \\\n",
      "0  Languages: Python, Java, C TensorFlow Keras Co...   \n",
      "1  Languages: C++, Java,Python, HTML/CSS, JavaScr...   \n",
      "2  • Programming Languages: C, C++, Python, Solid...   \n",
      "3  Languages: C++,Java,Object-OrientedProgramming...   \n",
      "\n",
      "                                           Education  \n",
      "0  Raj Kumar Goel Institute of Technology Ghaziab...  \n",
      "1  Raj kumar goel institute of technology (AKTU) ...  \n",
      "2  Degree Institute Board / University CGPA/Perce...  \n",
      "3  RajKumarGoelInstituteofTechnology(AKTU) Nov202...  \n",
      "\n",
      "----------------\n",
      "\n",
      "                      ID Category  \\\n",
      "0  Shivansh_Tyagi_Resume        1   \n",
      "1   Rajat_Gupta_Resume 1        2   \n",
      "2       Alok_kumar_yadav        3   \n",
      "3  SanchitChauhan_Rename        4   \n",
      "\n",
      "                                              Skills  \\\n",
      "0  Languages: Python, Java, C TensorFlow Keras Co...   \n",
      "1  Languages: C++, Java,Python, HTML/CSS, JavaScr...   \n",
      "2  • Programming Languages: C, C++, Python, Solid...   \n",
      "3  Languages: C++,Java,Object-OrientedProgramming...   \n",
      "\n",
      "                                           Education  \\\n",
      "0  Raj Kumar Goel Institute of Technology Ghaziab...   \n",
      "1  Raj kumar goel institute of technology (AKTU) ...   \n",
      "2  Degree Institute Board / University CGPA/Perce...   \n",
      "3  RajKumarGoelInstituteofTechnology(AKTU) Nov202...   \n",
      "\n",
      "                                                  CV  \n",
      "0  Languages: Python, Java, C TensorFlow Keras Co...  \n",
      "1  Languages: C++, Java,Python, HTML/CSS, JavaScr...  \n",
      "2  • Programming Languages: C, C++, Python, Solid...  \n",
      "3  Languages: C++,Java,Object-OrientedProgramming...  \n",
      "\n",
      "----------------\n",
      "\n",
      "                      ID Category  \\\n",
      "0  Shivansh_Tyagi_Resume        1   \n",
      "1   Rajat_Gupta_Resume 1        2   \n",
      "2       Alok_kumar_yadav        3   \n",
      "3  SanchitChauhan_Rename        4   \n",
      "\n",
      "                                              Skills  \\\n",
      "0  Languages: Python, Java, C TensorFlow Keras Co...   \n",
      "1  Languages: C++, Java,Python, HTML/CSS, JavaScr...   \n",
      "2  • Programming Languages: C, C++, Python, Solid...   \n",
      "3  Languages: C++,Java,Object-OrientedProgramming...   \n",
      "\n",
      "                                           Education  \\\n",
      "0  Raj Kumar Goel Institute of Technology Ghaziab...   \n",
      "1  Raj kumar goel institute of technology (AKTU) ...   \n",
      "2  Degree Institute Board / University CGPA/Perce...   \n",
      "3  RajKumarGoelInstituteofTechnology(AKTU) Nov202...   \n",
      "\n",
      "                                                  CV  \n",
      "0  languages python java c tensorflow keras convo...  \n",
      "1  languages c javapython htmlcss javascript chro...  \n",
      "2  programming languages c c python solidity   fr...  \n",
      "3  languages cjavaobjectorientedprogrammingincsql...  \n",
      "\n",
      "----------------\n",
      "\n",
      "Candidate dataset shape: (4, 5)\n",
      "CPU times: total: 1.02 s\n",
      "Wall time: 6.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_df = build_candidate_dataset(data_folder='Data_real')\n",
    "print(\"Candidate dataset shape:\", cv_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bc08f3e-2e85-434e-a601-43d9810dd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.to_csv('./pdf_extracted_skills_education.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e0770a6-d5ee-41e5-985a-a7277c4ab67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model_dir = \"./fine_tuned_t5_small\"\n",
    "tokenizer_extraction = T5Tokenizer.from_pretrained(extraction_model_dir)\n",
    "model_extraction = T5ForConditionalGeneration.from_pretrained(extraction_model_dir)\n",
    "model_extraction.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7f1a5ce-b373-41d7-909d-c660678ae448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_skills(job_description, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Extract skills from a job description using the fine-tuned T5 model.\n",
    "    \"\"\"\n",
    "    input_text = \"extract skills: \" + job_description\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True)\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    outputs = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "    generated_skills = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f365e74c-3caa-42cb-97a0-c760c07bd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_data = [\n",
    "    \"We are looking for a dynamic Full-Stack Developer proficient in modern web technologies including ExpressJS, ReactJS, NextJs, NodeJS, HTML, CSS, and JavaScript to build and maintain high-performance web applications. The ideal candidate will have a strong foundation in data management using MongoDB, PostgreSQL, and SQL, coupled with hands-on experience deploying and managing applications on cloud platforms such as AWS and Azure. This role demands a proactive problem-solver with excellent collaboration skills, ready to contribute to innovative projects in a fast-paced environment.\",\n",
    "    \"PhD in machine learning, computer science, statistics, biomedical informatics, or a related field relevant 9+ years of industry/academic experience in machine learning or a related fiel Hands-on experience in implementing and training machine learning algorithms and statistical analysis, including for example non-parametric tests, mixed linear models, modern supervised and unsupervised machine learning algorithms such as SVM, random forest, PCA, t-SNE, clustering, LMMs, and deep learning. Experience with Python, Spark (Databricks), DevOps Tools (Github Actions, Docker, etc.) Effective communication skills, including in an interdisciplinary environment Solid written communication skills of scientific material. Proven deep understanding of mathematical foundations of machine learning, including statistics, linear algebra, and computer science\"\n",
    "    # Add more job descriptions as needed...\n",
    "]\n",
    "jd_df = pd.DataFrame({\n",
    "    'position_title': [\n",
    "        \"React Developer\",\n",
    "        \"AI/Ml Developer\"\n",
    "    ],\n",
    "    'job_description': jd_data\n",
    "})\n",
    "# Clean the job description text\n",
    "jd_df['clean_jd'] = jd_df['job_description'].apply(text_cleaning)\n",
    "\n",
    "extracted_skills = jd_df['clean_jd'].apply(lambda x: generate_skills(x, tokenizer_extraction, model_extraction))\n",
    "jd_df['final_jd'] = jd_df['clean_jd'] + \" \" + extracted_skills\n",
    "# For the prototype, we use a subset (e.g. first 15 JDs)\n",
    "#num_jds = 15\n",
    "job_descriptions = jd_df['clean_jd'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fa9af85-11f4-4395-bb4f-1a0538293040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90cea356-fbdc-4c99-919a-f747ed5404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    \"\"\"Generate an embedding for a given text using mean pooling.\"\"\"\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    # Mean pooling over the sequence length dimension\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).numpy()[0]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "425e245f-57ba-4f33-843c-b1085b445e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for job descriptions...\n",
      "Generating embeddings for candidate CVs...\n",
      "CPU times: total: 3.73 s\n",
      "Wall time: 850 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Generating embeddings for job descriptions...\")\n",
    "jd_embeddings = [get_embedding(jd) for jd in job_descriptions]\n",
    "print(\"Generating embeddings for candidate CVs...\")\n",
    "resume_embeddings = [get_embedding(cv) for cv in cv_df['CV'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5ace06c-39b4-4057-a4e2-9ced4fbab6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD embedding shape: (768,)\n",
      "Resume embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(\"JD embedding shape:\", jd_embeddings[0].shape)\n",
    "print(\"Resume embedding shape:\", resume_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6aa6c08b-5a96-4389-9814-c38f6b352ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(jd_embeddings, resume_embeddings)\n",
    "\n",
    "# For each JD, pick the top N candidate indices based on similarity\n",
    "num_top_candidates = 5\n",
    "top_candidates = {}\n",
    "\n",
    "for jd_index, scores in enumerate(similarity_matrix):\n",
    "    candidate_indices = np.argsort(scores)[::-1][:num_top_candidates]\n",
    "    top_candidates[jd_index] = [(idx, scores[idx]) for idx in candidate_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b51f8b3-2a64-42fd-a676-a7808f0ae242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top candidates for JD 1 - Position: React Developer\n",
      "  Candidate 2 - Similarity Score: 0.8738 - 2/Rajat_Gupta_Resume 1.pdf\n",
      "  Candidate 1 - Similarity Score: 0.8423 - 1/Shivansh_Tyagi_Resume.pdf\n",
      "  Candidate 3 - Similarity Score: 0.8276 - 3/Alok_kumar_yadav.pdf\n",
      "  Candidate 4 - Similarity Score: 0.8238 - 4/SanchitChauhan_Rename.pdf\n",
      "\n",
      "Top candidates for JD 2 - Position: AI/Ml Developer\n",
      "  Candidate 1 - Similarity Score: 0.9155 - 1/Shivansh_Tyagi_Resume.pdf\n",
      "  Candidate 2 - Similarity Score: 0.8888 - 2/Rajat_Gupta_Resume 1.pdf\n",
      "  Candidate 3 - Similarity Score: 0.8444 - 3/Alok_kumar_yadav.pdf\n",
      "  Candidate 4 - Similarity Score: 0.8411 - 4/SanchitChauhan_Rename.pdf\n"
     ]
    }
   ],
   "source": [
    "for jd_index, candidate_list in top_candidates.items():\n",
    "    position_title = jd_df.loc[jd_index, 'position_title'] if jd_index < len(jd_df) else \"N/A\"\n",
    "    print(f\"\\nTop candidates for JD {jd_index+1} - Position: {position_title}\")\n",
    "    for candidate_index, score in candidate_list:\n",
    "        candidate_info = cv_df.iloc[candidate_index]\n",
    "        print(f\"  Candidate {candidate_index + 1} - Similarity Score: {score:.4f} - {candidate_info['Category']}/{candidate_info['ID']}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
