{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eca053d-76bc-4c00-88c4-9c214e3c170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shive\\.conda\\envs\\yolo_env1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import torch\n",
    "import contractions\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdcc81-6f7b-4f30-947a-b33c03b665a7",
   "metadata": {},
   "source": [
    "## Extract from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acbbeae-ac37-4bc2-90eb-ef8ec0a35c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(pdf_path):\n",
    "    \"\"\"Extract all text from a PDF file using pdfplumber.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            resume_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    resume_text += \" \" + page_text\n",
    "        return resume_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "808ef9a7-7be1-47f7-ae0f-74e3732c537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_information('Shivansh_Tyagi_Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7078971c-20aa-4a22-bdea-80ccb699b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shivansh Tyagi\n",
      "# shivelite2003@gmail.com (cid:132) +91-7456833022 (cid:240) Shivansh Tyagi § ShivanshTyagi9\n",
      "Summary\n",
      "SkilledinPython,dataanalysis,andmachinelearning,withexperienceinbuildingpredictivemodels,automation\n",
      "tools, and interactive applications.\n",
      "Education\n",
      "Raj Kumar Goel Institute of Technology Ghaziabad, UP\n",
      "B.Tech in Computer Science and Engineering Expeted Graduation, 2026\n",
      "◦ Concentrations: Computational Fundamentals\n",
      "◦ CGPA: 8\n",
      "◦ Coursework: Data Structure and Algorithms, Operating System, Database Management System, Com-\n",
      "puter Architecture, Machine Learning, OOPS\n",
      "Projects\n",
      "Handwritten-Digit-Recognition github repo 2\n",
      "◦ Used TensorFlow and Keras to develop a Convolutional Neural Network (CNN) for handwritten digit\n",
      "recognition with the MNIST dataset, achieving 99.12 accuracy, enhancing classification performance and\n",
      "model efficiency.\n",
      "◦ Used MNIST dataset to train the model.\n",
      "◦ Tools used: Python, NumPy, Pandas, Tensorflow / Keras, Matplotlib\n",
      "Fruits and Vegetable Classifier github repo 2\n",
      "◦ UsedResNetandEfficientNetarchitecturestoclassifyfruitsandvegetablesimages,achieving 96and94\n",
      "accuracy, which demonstrated effective generalization and model performance.\n",
      "◦ Performed hyperparameter tuning and applied data augmentation techniques to improve model robustness\n",
      "and enhance classification accuracy.\n",
      "◦ Worked with the Kaggle Fruits and Vegetables Image Recognition dataset, containing more than 33,000\n",
      "images in 36 classes, to train and evaluate the models.\n",
      "◦ TensorFlow, Python, and Matplotlib were used for modeling implementation, training, evaluation, and\n",
      "visualization of results.\n",
      "Spoti-Save github repo 2\n",
      "◦ EngineeredaPython-basedapplicationusingSpotifyAPItofetchlikedsongs,YouTubeDataAPIforvideo\n",
      "searches, and yt-dlp for mp3 downloads.\n",
      "◦ IntegratedmooddetectionthroughNLPtogeneratepersonalizedplaylistsbymappingSpotifyaudiofeatures\n",
      "to user mood.\n",
      "◦ Designed automated pipeline for storing metadata and optimizing batch processing for offline playback.\n",
      "Skills\n",
      "Languages: Python, Java, C\n",
      "Libraries: Pandas, Numpy, Tensorflow, Matplotlib, Flask\n",
      "Achievements\n",
      "◦ Rated 2 stars (1503 rating) on Codechef.\n",
      "◦ Rated Newbie(1127) on Codeforces.\n",
      "◦ Secured 1st place in college Code Clash event, awarded by Striver.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b299a8-5056-49d7-a8d6-dc35cb88dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details(resume_text):\n",
    "    \"\"\"Extract Skills and Education sections using regex.\"\"\"\n",
    "    # Pattern for Skills (assuming header \"Skills\" followed by newline)\n",
    "    skills_pattern = r'Skills\\n([\\s\\S]*?)(?=\\n[A-Z]|$)'\n",
    "    # Pattern for Education (assuming header \"Education\" followed by newline)\n",
    "    education_pattern = r'Education\\n([\\s\\S]*?)(?=\\n[A-Z][a-z]*\\n|$)'\n",
    "    \n",
    "    skills_match = re.findall(skills_pattern, resume_text, re.DOTALL)\n",
    "    education_match = re.findall(education_pattern, resume_text, re.DOTALL)\n",
    "    \n",
    "    skills = skills_match[0] if skills_match else \"\"\n",
    "    education = education_match[0] if education_match else \"\"\n",
    "    \n",
    "    return {'Skills': skills, 'Education': education}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d47b559-b107-47b8-be4b-6b4f64bda1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = extract_details(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8049b7ce-ca1c-425e-bbc2-49d973343505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Skills': 'Languages: Python, Java, C', 'Education': 'Raj Kumar Goel Institute of Technology Ghaziabad, UP\\nB.Tech in Computer Science and Engineering Expeted Graduation, 2026\\n◦ Concentrations: Computational Fundamentals\\n◦ CGPA: 8\\n◦ Coursework: Data Structure and Algorithms, Operating System, Database Management System, Com-\\nputer Architecture, Machine Learning, OOPS'}\n"
     ]
    }
   ],
   "source": [
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8036b855-ddef-4c15-b1e0-5ea1b7fb79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text for embedding.\"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    # Lowercase and trim\n",
    "    text = text.lower().strip()\n",
    "    # Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    # Remove URLs, emails, phone numbers\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\b\\d{1,3}[-./]?\\d{1,3}[-./]?\\d{1,4}\\b', '', text)\n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68637fdc-722f-4a98-bd6b-d33bf528f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def build_candidate_dataset(data_folder='data'):\n",
    "    \"\"\"\n",
    "    Walk through the data folder (with subfolders by category),\n",
    "    extract resume text from each PDF, extract details (Skills, Education),\n",
    "    and store metadata.\n",
    "    \"\"\"\n",
    "    candidate_data = []\n",
    "    for category in os.listdir(data_folder):\n",
    "        category_path = os.path.join(data_folder, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            for file in os.listdir(category_path):\n",
    "                if file.lower().endswith('.pdf'):\n",
    "                    pdf_path = os.path.join(category_path, file)\n",
    "                    full_text = extract_information(pdf_path)\n",
    "                    details = extract_details(full_text)\n",
    "                    # Use filename (without extension) as unique ID\n",
    "                    candidate_id = os.path.splitext(file)[0]\n",
    "                    candidate_data.append({\n",
    "                        'ID': candidate_id,\n",
    "                        'Category': category,\n",
    "                        'Skills': details.get('Skills', ''),\n",
    "                        'Education': details.get('Education', '')\n",
    "                    })\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(candidate_data)\n",
    "    # Optionally, remove resumes where both Skills and Education are missing\n",
    "    df = df[~((df['Skills'] == \"\") & (df['Education'] == \"\"))].reset_index(drop=True)\n",
    "    # Concatenate Skills and Education to form the complete CV text\n",
    "    df['CV'] = (df['Skills'] + \" \" + df['Education']).fillna(\"\")\n",
    "    # Clean the concatenated CV text\n",
    "    df['CV'] = df['CV'].apply(text_cleaning)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8306d191-9360-47a9-b02c-ec24f4144467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate dataset shape: (2460, 5)\n"
     ]
    }
   ],
   "source": [
    "cv_df = build_candidate_dataset(data_folder='data')\n",
    "print(\"Candidate dataset shape:\", cv_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc08f3e-2e85-434e-a601-43d9810dd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.to_csv('./pdf_extracted_skills_education.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f365e74c-3caa-42cb-97a0-c760c07bd21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shive\\.conda\\envs\\yolo_env1\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shive\\.cache\\huggingface\\hub\\datasets--jacob-hugging-face--job-descriptions. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|███████████████████████████████████████████████| 853/853 [00:00<00:00, 6147.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "jd_data = load_dataset('jacob-hugging-face/job-descriptions', split=\"train\")\n",
    "jd_df = pd.DataFrame(jd_data)\n",
    "# Clean the job description text\n",
    "jd_df['clean_jd'] = jd_df['job_description'].apply(text_cleaning)\n",
    "# For the prototype, we use a subset (e.g. first 15 JDs)\n",
    "num_jds = 15\n",
    "job_descriptions = jd_df['clean_jd'][:num_jds].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fa9af85-11f4-4395-bb4f-1a0538293040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shive\\.conda\\envs\\yolo_env1\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shive\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.eval()  # Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90cea356-fbdc-4c99-919a-f747ed5404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    \"\"\"Generate an embedding for a given text using mean pooling.\"\"\"\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    # Mean pooling over the sequence length dimension\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).numpy()[0]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "425e245f-57ba-4f33-843c-b1085b445e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for job descriptions...\n",
      "Generating embeddings for candidate CVs...\n",
      "CPU times: total: 13min 20s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Generating embeddings for job descriptions...\")\n",
    "jd_embeddings = [get_embedding(jd) for jd in job_descriptions]\n",
    "print(\"Generating embeddings for candidate CVs...\")\n",
    "resume_embeddings = [get_embedding(cv) for cv in cv_df['CV'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ace06c-39b4-4057-a4e2-9ced4fbab6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD embedding shape: (768,)\n",
      "Resume embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(\"JD embedding shape:\", jd_embeddings[0].shape)\n",
    "print(\"Resume embedding shape:\", resume_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa6c08b-5a96-4389-9814-c38f6b352ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(jd_embeddings, resume_embeddings)\n",
    "\n",
    "# For each JD, pick the top N candidate indices based on similarity\n",
    "num_top_candidates = 5\n",
    "top_candidates = {}\n",
    "\n",
    "for jd_index, scores in enumerate(similarity_matrix):\n",
    "    candidate_indices = np.argsort(scores)[::-1][:num_top_candidates]\n",
    "    top_candidates[jd_index] = [(idx, scores[idx]) for idx in candidate_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b51f8b3-2a64-42fd-a676-a7808f0ae242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top candidates for JD 1 - Position: Sales Specialist\n",
      "  Candidate 1942 - Similarity Score: 0.9415 - HR/18827609.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9388 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 28 - Similarity Score: 0.9377 - ACCOUNTANT/16237710.pdf\n",
      "  Candidate 1796 - Similarity Score: 0.9314 - HEALTHCARE/10466208.pdf\n",
      "  Candidate 2145 - Similarity Score: 0.9303 - PUBLIC-RELATIONS/12237267.pdf\n",
      "\n",
      "Top candidates for JD 2 - Position: Apple Solutions Consultant\n",
      "  Candidate 168 - Similarity Score: 0.9236 - ADVOCATE/22391901.pdf\n",
      "  Candidate 904 - Similarity Score: 0.9165 - BUSINESS-DEVELOPMENT/95382114.pdf\n",
      "  Candidate 1724 - Similarity Score: 0.9159 - FITNESS/21238396.pdf\n",
      "  Candidate 950 - Similarity Score: 0.9155 - CHEF/21869994.pdf\n",
      "  Candidate 482 - Similarity Score: 0.9146 - ARTS/54100393.pdf\n",
      "\n",
      "Top candidates for JD 3 - Position: Licensing Coordinator - Consumer Products\n",
      "  Candidate 2145 - Similarity Score: 0.9496 - PUBLIC-RELATIONS/12237267.pdf\n",
      "  Candidate 1186 - Similarity Score: 0.9458 - CONSULTANT/26234972.pdf\n",
      "  Candidate 1796 - Similarity Score: 0.9428 - HEALTHCARE/10466208.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9423 - HR/18827609.pdf\n",
      "  Candidate 1152 - Similarity Score: 0.9409 - CONSULTANT/15119529.pdf\n",
      "\n",
      "Top candidates for JD 4 - Position: Web Designer\n",
      "  Candidate 1276 - Similarity Score: 0.9487 - DESIGNER/18979238.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9438 - HR/18827609.pdf\n",
      "  Candidate 1006 - Similarity Score: 0.9357 - CHEF/53265899.pdf\n",
      "  Candidate 2435 - Similarity Score: 0.9341 - TEACHER/37660306.pdf\n",
      "  Candidate 1991 - Similarity Score: 0.9332 - HR/32896934.pdf\n",
      "\n",
      "Top candidates for JD 5 - Position: Web Developer\n",
      "  Candidate 291 - Similarity Score: 0.9501 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1276 - Similarity Score: 0.9446 - DESIGNER/18979238.pdf\n",
      "  Candidate 1364 - Similarity Score: 0.9408 - DIGITAL-MEDIA/14761906.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9378 - HR/18827609.pdf\n",
      "  Candidate 482 - Similarity Score: 0.9366 - ARTS/54100393.pdf\n",
      "\n",
      "Top candidates for JD 6 - Position: Frontend Web Developer\n",
      "  Candidate 1724 - Similarity Score: 0.9244 - FITNESS/21238396.pdf\n",
      "  Candidate 1354 - Similarity Score: 0.9191 - DIGITAL-MEDIA/11270462.pdf\n",
      "  Candidate 2246 - Similarity Score: 0.9169 - SALES/10464113.pdf\n",
      "  Candidate 482 - Similarity Score: 0.9167 - ARTS/54100393.pdf\n",
      "  Candidate 1276 - Similarity Score: 0.9154 - DESIGNER/18979238.pdf\n",
      "\n",
      "Top candidates for JD 7 - Position: Remote Website Designer\n",
      "  Candidate 1942 - Similarity Score: 0.9590 - HR/18827609.pdf\n",
      "  Candidate 2145 - Similarity Score: 0.9581 - PUBLIC-RELATIONS/12237267.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9574 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1152 - Similarity Score: 0.9518 - CONSULTANT/15119529.pdf\n",
      "  Candidate 1890 - Similarity Score: 0.9509 - HEALTHCARE/58879993.pdf\n",
      "\n",
      "Top candidates for JD 8 - Position: Web Designer\n",
      "  Candidate 1942 - Similarity Score: 0.9530 - HR/18827609.pdf\n",
      "  Candidate 2145 - Similarity Score: 0.9480 - PUBLIC-RELATIONS/12237267.pdf\n",
      "  Candidate 482 - Similarity Score: 0.9469 - ARTS/54100393.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9467 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1796 - Similarity Score: 0.9451 - HEALTHCARE/10466208.pdf\n",
      "\n",
      "Top candidates for JD 9 - Position: Web Designer\n",
      "  Candidate 291 - Similarity Score: 0.9542 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9494 - HR/18827609.pdf\n",
      "  Candidate 1152 - Similarity Score: 0.9447 - CONSULTANT/15119529.pdf\n",
      "  Candidate 2164 - Similarity Score: 0.9434 - PUBLIC-RELATIONS/16620172.pdf\n",
      "  Candidate 1364 - Similarity Score: 0.9432 - DIGITAL-MEDIA/14761906.pdf\n",
      "\n",
      "Top candidates for JD 10 - Position: SR. Web Designer\n",
      "  Candidate 291 - Similarity Score: 0.9570 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9490 - HR/18827609.pdf\n",
      "  Candidate 1755 - Similarity Score: 0.9488 - FITNESS/29792535.pdf\n",
      "  Candidate 1458 - Similarity Score: 0.9483 - ENGINEERING/12518008.pdf\n",
      "  Candidate 170 - Similarity Score: 0.9479 - ADVOCATE/23577836.pdf\n",
      "\n",
      "Top candidates for JD 11 - Position: Web Developer\n",
      "  Candidate 1942 - Similarity Score: 0.9611 - HR/18827609.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9564 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1152 - Similarity Score: 0.9562 - CONSULTANT/15119529.pdf\n",
      "  Candidate 2145 - Similarity Score: 0.9556 - PUBLIC-RELATIONS/12237267.pdf\n",
      "  Candidate 2026 - Similarity Score: 0.9527 - INFORMATION-TECHNOLOGY/11957080.pdf\n",
      "\n",
      "Top candidates for JD 12 - Position: Web Developer\n",
      "  Candidate 1276 - Similarity Score: 0.9449 - DESIGNER/18979238.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9448 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9433 - HR/18827609.pdf\n",
      "  Candidate 482 - Similarity Score: 0.9419 - ARTS/54100393.pdf\n",
      "  Candidate 1006 - Similarity Score: 0.9411 - CHEF/53265899.pdf\n",
      "\n",
      "Top candidates for JD 13 - Position: Senior UI Designer\n",
      "  Candidate 1276 - Similarity Score: 0.9446 - DESIGNER/18979238.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9428 - HR/18827609.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9390 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 482 - Similarity Score: 0.9370 - ARTS/54100393.pdf\n",
      "  Candidate 1186 - Similarity Score: 0.9363 - CONSULTANT/26234972.pdf\n",
      "\n",
      "Top candidates for JD 14 - Position: Wordpress Web Developer\n",
      "  Candidate 1304 - Similarity Score: 0.9450 - DESIGNER/26790545.pdf\n",
      "  Candidate 2083 - Similarity Score: 0.9286 - INFORMATION-TECHNOLOGY/26768723.pdf\n",
      "  Candidate 1228 - Similarity Score: 0.9286 - CONSULTANT/65062795.pdf\n",
      "  Candidate 1412 - Similarity Score: 0.9174 - DIGITAL-MEDIA/27981289.pdf\n",
      "  Candidate 238 - Similarity Score: 0.9129 - AGRICULTURE/11676151.pdf\n",
      "\n",
      "Top candidates for JD 15 - Position: UI Web Designer\n",
      "  Candidate 482 - Similarity Score: 0.9563 - ARTS/54100393.pdf\n",
      "  Candidate 1276 - Similarity Score: 0.9516 - DESIGNER/18979238.pdf\n",
      "  Candidate 291 - Similarity Score: 0.9499 - AGRICULTURE/62994611.pdf\n",
      "  Candidate 402 - Similarity Score: 0.9469 - ARTS/12413512.pdf\n",
      "  Candidate 1942 - Similarity Score: 0.9447 - HR/18827609.pdf\n"
     ]
    }
   ],
   "source": [
    "for jd_index, candidate_list in top_candidates.items():\n",
    "    position_title = jd_df.loc[jd_index, 'position_title'] if jd_index < len(jd_df) else \"N/A\"\n",
    "    print(f\"\\nTop candidates for JD {jd_index+1} - Position: {position_title}\")\n",
    "    for candidate_index, score in candidate_list:\n",
    "        candidate_info = cv_df.iloc[candidate_index]\n",
    "        print(f\"  Candidate {candidate_index + 1} - Similarity Score: {score:.4f} - {candidate_info['Category']}/{candidate_info['ID']}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a0584-6cfa-4317-9b41-dc8994c46d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
